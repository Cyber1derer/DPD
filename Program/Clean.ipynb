{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import defaultdict,Counter\n",
    "\n",
    "import scipy.io\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Data.DPDBlocks.blocks import AFIR, Delay, Prod_cmp, ABS, Polynomial\n",
    "from Data.utilits.calculate_functions import ACPR_calc, MSE, NMSE\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 64\n",
    "name = 'work/VorkutovDA/Data/BlackBoxData/BlackBoxData_80'\n",
    "# name = 'BlackBoxData'\n",
    "# name = '../BlackBoxData/data1'\n",
    "mat = scipy.io.loadmat(name)\n",
    "x = np.array(mat['x']).reshape(-1,1)/2**15\n",
    "d = np.array(mat['y']).reshape(-1,1)/2**15\n",
    "# x = np.array(mat['xE']).reshape(-1,1)/2**15\n",
    "# d = np.array(mat['d']).reshape(-1,1)/2**15\n",
    "# x, d = mat['xE'], mat['d']\n",
    "x_real, x_imag = torch.from_numpy(np.real(x)), torch.from_numpy(np.imag(x))\n",
    "d_real, d_imag = torch.from_numpy(np.real(d)), torch.from_numpy(np.imag(d))\n",
    "X = torch.DoubleTensor(torch.cat((x_real, x_imag), dim=1)).reshape(-1,2,1)\n",
    "D = torch.DoubleTensor(torch.cat((d_real, d_imag), dim=1)).reshape(-1,2,1)\n",
    "\n",
    "train_queue = torch.utils.data.DataLoader(\n",
    "    torch.cat((X,D),dim=-1), batch_size=Batch_size)#, pin_memory=True)\n",
    "\n",
    "valid_queue = torch.utils.data.DataLoader(\n",
    "    torch.cat((X,D),dim=-1), batch_size=X.shape[0])#,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewDAtaLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(valid_queue )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict,Counter\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from Data.DPDBlocks.blocks import AFIR,ABS,Polynomial,Delay,Prod_cmp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def eval_model(valid_queue, model, criterion):\n",
    "    for step, (valid) in enumerate(valid_queue):\n",
    "        model.eval()\n",
    "        input_batch = Variable(valid[:,:,:1],requires_grad=False).permute(2,1,0).cpu()\n",
    "        desired = Variable(valid[:,:,1:],requires_grad=False).permute(2,1,0).cpu()\n",
    "        #out = model.forward(input_batch)\n",
    "        out = sum(list(map( lambda n: n(input_batch),  model)))\n",
    "\n",
    "        loss=criterion(out,desired)\n",
    "        #draw_spectrum(input_batch,desired,out)\n",
    "        accuracy = NMSE(input_batch, out - desired)\n",
    "\n",
    "    return loss,accuracy\n",
    "\n",
    "def train_of_epoch(train_queue, model, criterion, optimizer):\n",
    "    \n",
    "\n",
    "    \n",
    "    for step, (train) in enumerate(train_queue):\n",
    "\n",
    "        input_batch = Variable(train[:,:,:1],requires_grad=False).permute(2,1,0).cpu()\n",
    "        desired = Variable(train[:,:,1:],requires_grad=False).permute(2,1,0).cpu()\n",
    "        optimizer.zero_grad()\n",
    "        #out = model.forward(input_batch)\n",
    "        out = sum(list(map( lambda n: n(input_batch),  model)))\n",
    "\n",
    "        loss = criterion(out, desired)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def train(train_queue, valid_queue, model, criterion, optimizer,n_epoch,\n",
    "          scheduler,log_every=1,save_flag=True,path_to_experiment='', dataFromEpohAccuracy = [], dataFromEpohLoss = []):\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    min_loss=0\n",
    "    hist=defaultdict(list)\n",
    "    t0=timer()\n",
    "    for it in tqdm (range(n_epoch)):\n",
    "        model.train(True)\n",
    "        train_of_epoch(train_queue, model, criterion, optimizer)\n",
    "        scheduler.step()\n",
    "        if it%log_every==0:\n",
    "            loss_v,accuracy_v=eval_model(valid_queue, model, loss_fn)\n",
    "            print('Loss = ',loss_v.cpu().detach().numpy(), 'Accuracy = ', accuracy_v.cpu().detach().numpy(), 'dbs')\n",
    "            dataFromEpohAccuracy.append(accuracy_v)\n",
    "            dataFromEpohLoss.append(loss_v)\n",
    "            \n",
    "            if save_flag:\n",
    "                with open(path_to_experiment + '/hist.pkl', 'wb') as output:\n",
    "                    pickle.dump(hist, output)\n",
    "\n",
    "                    torch.save(model.state_dict(), path_to_experiment + '/model.pt')\n",
    "                if hist['train_loss_db'][-1] < min_loss:\n",
    "                            min_loss = hist['train_loss_db'][-1]\n",
    "                            torch.save(model.state_dict(), path_to_experiment + '/best_model.pth')\n",
    "\n",
    "#class Cell_try_2(nn.Module):\n",
    "#    def __init__(self,M=15,D=0,Poly_order=8,Passthrough=False):\n",
    "#        super(Cell_try_2,self).__init__()\n",
    "#        self.f = AFIR(M,0)\n",
    "#        self.pol = Polynomial(Poly_order,Passthrough)\n",
    "#        self.prod = Prod_cmp()\n",
    "#        self.delay = Delay(D)\n",
    "#    def forward(self,x):\n",
    "#        #return self.prod(self.f(self.delay(x)), self.pol(self.delay(x)))\n",
    "#        return self.prod( self.f(x), self.pol(self.f(self.delay(x))) )\n",
    "class Cell_try_2(nn.Module):\n",
    "    def __init__(self,M=15,D=0,Poly_order=8,Passthrough=False):\n",
    "        super(Cell_try_2,self).__init__()\n",
    "        self.f = AFIR(M,0)\n",
    "        self.pol = Polynomial(Poly_order,Passthrough)\n",
    "        self.prod = Prod_cmp()\n",
    "        self.delay = Delay(D)\n",
    "    def forward(self,x):\n",
    "        #return self.prod(self.f(self.delay(x)), self.pol(self.delay(x)))\n",
    "        return self.prod( self.f(self.delay(x)), self.f(self.pol(self.delay(x))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {'p': [4, 5, 6, 7, 8, 9], 'k' : [3, 5, 7, 9], 'z' : [-2, -1, 0, 1, 2]}\n",
    "ex_D = {} # extremum vals of D\n",
    "step_size=10\n",
    "gamma=0.1\n",
    "for key in D.keys():\n",
    "  ex_D[key] = [ min(D[key]), max(D[key])]\n",
    "\n",
    "# complex reference model\n",
    "ref_model = {'k': [9,5,9,7,9],'p': [9,8,6,9,6]}\n",
    "\n",
    "### params of the functional\n",
    "score_huge = -37\n",
    "score_min = -20.0\n",
    "complex_huge = 2 * ( sum(ref_model['k']) + sum(ref_model['p']) )\n",
    "complex_min = 2 * (4 * 5 + 3 * 5)\n",
    "trtr_coef = 0.4\n",
    "\n",
    "def objective(trial):\n",
    "  # create and train NN\n",
    "  net = torch.nn.ModuleList()\n",
    "\n",
    "  complex_cur = 0\n",
    "\n",
    "  for i in range(2):\n",
    "    # det hyperparams \n",
    "    poly_ord = trial.suggest_int('p'+str(i), ex_D['p'][0], ex_D['p'][1])\n",
    "    conv_ord = trial.suggest_int('k'+str(i), ex_D['k'][0], ex_D['k'][1], step=2)\n",
    "    net.append(Cell_try_2(M=conv_ord, D=(ex_D['z'][0] + 1*i), Poly_order=poly_ord))\n",
    "    complex_cur = complex_cur + poly_ord + conv_ord\n",
    "\n",
    "  net = net.to(torch.device('cpu'))\n",
    "  optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "  train(train_queue, valid_queue, net, loss_fn, optimizer, 20, scheduler, save_flag=False)\n",
    "\n",
    "  loss_cur, accuracy_cur = eval_model(valid_queue, net, loss_fn)\n",
    "  score_cur = accuracy_cur.item()\n",
    "\n",
    "  #return score_cur\n",
    "  return  (complex_cur - complex_min) / (complex_huge - complex_min) + trtr_coef * (score_huge - score_cur) / (score_huge - score_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_study(sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(), direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mHyperbandPruner())\n\u001b[1;32m      2\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction=\"minimize\", pruner=optuna.pruners.HyperbandPruner())\n",
    "study.optimize(objective, n_trials=1)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "D = {'p': [4, 5, 6, 7, 8, 9], 'k' : [3, 5, 7, 9], 'z' : [-2, -1, 0, 1, 2]}\n",
    "ex_D = {} # extremum vals of D\n",
    "\n",
    "for key in D.keys():\n",
    "  ex_D[key] = [ min(D[key]), max(D[key])]\n",
    "  \n",
    "# complex reference model\n",
    "ref_model = {'k': [9,5,9,7,9],'p': [9,8,6,9,6]}\n",
    "\n",
    "### params of the functional\n",
    "score_huge = -33.88\n",
    "score_min = -20.0\n",
    "complex_huge = sum(ref_model['k']) + sum(ref_model['p'])\n",
    "complex_min = 4 * 5 + 3 * 5\n",
    "trtr_coef = 0.4\n",
    "gamma=0.95\n",
    "step_size=5\n",
    "\n",
    "COMP_2 = []\n",
    "SCR_2 = []\n",
    "zz = [-3,-2,-1,2,3]\n",
    "\n",
    "\n",
    "net = torch.nn.ModuleList()\n",
    "complex_cur = 0\n",
    "\n",
    "#TPE\n",
    "net.append(Cell_try_2(M=9, D=zz[0], Poly_order=5))\n",
    "net.append(Cell_try_2(M=7, D=zz[1], Poly_order=9))\n",
    "net.append(Cell_try_2(M=7, D=zz[2], Poly_order=9))\n",
    "net.append(Cell_try_2(M=8, D=zz[3], Poly_order=9))\n",
    "net.append(Cell_try_2(M=7, D=zz[4], Poly_order=6))\n",
    "\n",
    "\n",
    "\n",
    "net = net.to(torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "net.train()\n",
    "\n",
    "train( train_queue, valid_queue, net, loss_fn, optimizer,20,scheduler,save_flag=False)\n",
    "\n",
    "loss_cur, accuracy_cur = eval_model(valid_queue, net, loss_fn)\n",
    "score_cur = accuracy_cur.item()\n",
    "\n",
    "COMP_2.append(complex_cur)\n",
    "SCR_2.append(score_cur)\n",
    "\n",
    "print( score_cur)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TPESampler\n",
    "netTPE = torch.nn.ModuleList()\n",
    "complex_cur = 0\n",
    "COMP_netTPE = []\n",
    "SCR_netTPE = []\n",
    "dataFromEpohAccuracyTPE = []\n",
    "dataFromEpohLossTPE = []\n",
    "\n",
    "netTPE.append(Cell_try_2(M=9, D=zz[0], Poly_order=5))\n",
    "netTPE.append(Cell_try_2(M=7, D=zz[1], Poly_order=9))\n",
    "netTPE.append(Cell_try_2(M=7, D=zz[2], Poly_order=9))\n",
    "netTPE.append(Cell_try_2(M=9, D=zz[3], Poly_order=8))\n",
    "netTPE.append(Cell_try_2(M=7, D=zz[4], Poly_order=6))\n",
    "\n",
    "\n",
    "netTPE = netTPE.to(torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(netTPE.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "netTPE.train()\n",
    "\n",
    "train( train_queue, valid_queue, netTPE, loss_fn, optimizer,50,scheduler,save_flag=False, dataFromEpohAccuracy = dataFromEpohAccuracyTPE, dataFromEpohLoss =dataFromEpohLossTPE )\n",
    "\n",
    "loss_cur, accuracy_cur = eval_model(valid_queue, netTPE, loss_fn)\n",
    "score_cur = accuracy_cur.item()\n",
    "\n",
    "COMP_netTPE.append(complex_cur)\n",
    "SCR_netTPE.append(score_cur)\n",
    "\n",
    "print( score_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newListTPE = [] \n",
    "for i in dataFromEpohAccuracyTPE:\n",
    "    newListTPE.append((i.cpu().detach().numpy()) )\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(newList)\n",
    "plt.savefig(\"TPETrain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newList2 = [] \n",
    "for i in dataFromEpohAccuracyTPE:\n",
    "    newList2.append((i.cpu().detach().numpy()) )\n",
    "plt.plot(newList2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomSampler\n",
    "netRandom = torch.nn.ModuleList()\n",
    "complex_cur = 0\n",
    "COMP_netRandom = []\n",
    "SCR_netRandom = []\n",
    "\n",
    "dataFromEpohAccuracyRandom = []\n",
    "dataFromEpohLossRandom = []\n",
    "\n",
    "netRandom.append(Cell_try_2(M=9, D=zz[0], Poly_order=8))\n",
    "netRandom.append(Cell_try_2(M=5, D=zz[1], Poly_order=8))\n",
    "netRandom.append(Cell_try_2(M=7, D=zz[2], Poly_order=7))\n",
    "netRandom.append(Cell_try_2(M=5, D=zz[3], Poly_order=9))\n",
    "netRandom.append(Cell_try_2(M=3, D=zz[4], Poly_order=5))\n",
    "\n",
    "\n",
    "\n",
    "netRandom = netRandom.to(torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(netRandom.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "netRandom.train()\n",
    "\n",
    "train( train_queue, valid_queue, netRandom, loss_fn, optimizer,20,scheduler,save_flag=False,  dataFromEpohAccuracy = dataFromEpohAccuracyRandom, dataFromEpohLoss =dataFromEpohLossRandom )\n",
    "\n",
    "loss_cur, accuracy_cur = eval_model(valid_queue, netRandom, loss_fn)\n",
    "score_cur = accuracy_cur.item()\n",
    "\n",
    "COMP_netRandom.append(complex_cur)\n",
    "SCR_netRandom.append(score_cur)\n",
    "\n",
    "print( score_cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newListRandom = [] \n",
    "for i in dataFromEpohAccuracyRandom:\n",
    "    newListRandom.append((i.cpu().detach().numpy()) )\n",
    "newListRandom = sorted(newListRandom, reverse=True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(newListRandom)\n",
    "plt.savefig(\"RandomTrain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QMCSampler\n",
    "netQMC = torch.nn.ModuleList()\n",
    "complex_cur = 0\n",
    "COMP_netQMC = []\n",
    "SCR_netQMC = []\n",
    "\n",
    "\n",
    "dataFromEpohAccuracyQMC = []\n",
    "dataFromEpohLossQMC = []\n",
    "\n",
    "\n",
    "netQMC.append(Cell_try_2(M=9, D=zz[0], Poly_order=6))\n",
    "netQMC.append(Cell_try_2(M=7, D=zz[1], Poly_order=6))\n",
    "netQMC.append(Cell_try_2(M=9, D=zz[2], Poly_order=8))\n",
    "netQMC.append(Cell_try_2(M=7, D=zz[3], Poly_order=9))\n",
    "netQMC.append(Cell_try_2(M=5, D=zz[4], Poly_order=7))\n",
    "\n",
    "\n",
    "\n",
    "netQMC = netQMC.to(torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(netQMC.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "netQMC.train()\n",
    "\n",
    "train( train_queue, valid_queue, netQMC, loss_fn, optimizer,20,scheduler,save_flag=False,  dataFromEpohAccuracy = dataFromEpohAccuracyQMC, dataFromEpohLoss =dataFromEpohLossQMC )\n",
    "\n",
    "loss_cur, accuracy_cur = eval_model(valid_queue, netQMC, loss_fn)\n",
    "score_cur = accuracy_cur.item()\n",
    "\n",
    "COMP_netQMC.append(complex_cur)\n",
    "SCR_netQMC.append(score_cur)\n",
    "\n",
    "print( score_cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newListQMC = [] \n",
    "for i in dataFromEpohAccuracyQMC:\n",
    "    newListQMC.append((i.cpu().detach().numpy()) )\n",
    "newListQMC = sorted(newListQMC, reverse=True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(newListQMC)\n",
    "plt.savefig(\"QMCTrain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NSGAIISampler\n",
    "netNSGAII = torch.nn.ModuleList()\n",
    "complex_cur = 0\n",
    "COMP_netNSGAII = []\n",
    "SCR_netNSGAII = []\n",
    "\n",
    "dataFromEpohAccuracyNSGAII = []\n",
    "dataFromEpohLossNSGAII = []\n",
    "\n",
    "\n",
    "netNSGAII.append(Cell_try_2(M=7, D=zz[0], Poly_order=8))\n",
    "netNSGAII.append(Cell_try_2(M=5, D=zz[1], Poly_order=7))\n",
    "netNSGAII.append(Cell_try_2(M=5, D=zz[2], Poly_order=8))\n",
    "netNSGAII.append(Cell_try_2(M=7, D=zz[3], Poly_order=8))\n",
    "netNSGAII.append(Cell_try_2(M=5, D=zz[4], Poly_order=5))\n",
    "\n",
    "\n",
    "\n",
    "netNSGAII = netNSGAII.to(torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(netNSGAII.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "netNSGAII.train()\n",
    "\n",
    "train( train_queue, valid_queue, netNSGAII, loss_fn, optimizer,20,scheduler,save_flag=False, dataFromEpohAccuracy = dataFromEpohAccuracyNSGAII, dataFromEpohLoss =dataFromEpohLossNSGAII)\n",
    "\n",
    "loss_cur, accuracy_cur = eval_model(valid_queue, netNSGAII, loss_fn)\n",
    "score_cur = accuracy_cur.item()\n",
    "\n",
    "COMP_netNSGAII.append(complex_cur)\n",
    "SCR_netNSGAII.append(score_cur)\n",
    "\n",
    "print( score_cur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newListQMC = [] \n",
    "for i in dataFromEpohAccuracyNSGAII:\n",
    "    newListQMC.append((i.cpu().detach().numpy()) )\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "newListNSGAII = newListQMC\n",
    "plt.plot(newListNSGAII)\n",
    "\n",
    "plt.savefig(\"NSGAIITrain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CMA-EASampler\n",
    "\n",
    "netCMA_EA = torch.nn.ModuleList()\n",
    "complex_cur = 0\n",
    "COMP_netCMA_EA = []\n",
    "SCR_netCMA_EA = []\n",
    "\n",
    "\n",
    "dataFromEpohAccuracyCMA = []\n",
    "dataFromEpohLossCMA = []\n",
    "\n",
    "netCMA_EA.append(Cell_try_2(M=5, D=zz[0], Poly_order=6))\n",
    "netCMA_EA.append(Cell_try_2(M=7, D=zz[1], Poly_order=6))\n",
    "netCMA_EA.append(Cell_try_2(M=7, D=zz[2], Poly_order=7))\n",
    "netCMA_EA.append(Cell_try_2(M=7, D=zz[3], Poly_order=6))\n",
    "netCMA_EA.append(Cell_try_2(M=7, D=zz[4], Poly_order=8))\n",
    "\n",
    "\n",
    "\n",
    "netCMA_EA = netCMA_EA.to(torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(netCMA_EA.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "netCMA_EA.train()\n",
    "\n",
    "train( train_queue, valid_queue, netCMA_EA, loss_fn, optimizer,20,scheduler,save_flag=False,  dataFromEpohAccuracy = dataFromEpohAccuracyCMA, dataFromEpohLoss =dataFromEpohLossCMA)\n",
    "\n",
    "loss_cur, accuracy_cur = eval_model(valid_queue, netCMA_EA, loss_fn)\n",
    "score_cur = accuracy_cur.item()\n",
    "\n",
    "COMP_netCMA_EA.append(complex_cur)\n",
    "SCR_netCMA_EA.append(score_cur)\n",
    "\n",
    "print( score_cur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newListQMC = [] \n",
    "for i in dataFromEpohAccuracyCMA:\n",
    "    newListQMC.append((i.cpu().detach().numpy()) )\n",
    "newListQMC = sorted(newListQMC, reverse=True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"CMA-E\")\n",
    "newListCMA = newListQMC\n",
    "plt.plot(newListCMA)\n",
    "plt.savefig(\"CMATrain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Huge\n",
    "\n",
    "netHuge = torch.nn.ModuleList()\n",
    "complex_cur = 0\n",
    "COMP_netHuge = []\n",
    "SCR_netHuge = []\n",
    "\n",
    "dataFromEpohAccuracyHuge = []\n",
    "dataFromEpohLossHuge = []\n",
    "\n",
    "\n",
    "netHuge.append(Cell_try_2(M=9, D=zz[0], Poly_order=9))\n",
    "netHuge.append(Cell_try_2(M=9, D=zz[1], Poly_order=9))\n",
    "netHuge.append(Cell_try_2(M=9, D=zz[2], Poly_order=9))\n",
    "netHuge.append(Cell_try_2(M=9, D=zz[3], Poly_order=9))\n",
    "netHuge.append(Cell_try_2(M=9, D=zz[4], Poly_order=9))\n",
    "\n",
    "\n",
    "\n",
    "netHuge = netHuge.to(torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(netHuge.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "netHuge.train()\n",
    "\n",
    "train( train_queue, valid_queue, netHuge, loss_fn, optimizer,20,scheduler,save_flag=False, dataFromEpohAccuracy = dataFromEpohAccuracyHuge, dataFromEpohLoss =dataFromEpohLossHuge)\n",
    "\n",
    "loss_cur, accuracy_cur = eval_model(valid_queue, netHuge, loss_fn)\n",
    "score_cur = accuracy_cur.item()\n",
    "\n",
    "COMP_netHuge.append(complex_cur)\n",
    "SCR_netHuge.append(score_cur)\n",
    "\n",
    "print( score_cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newListHuge = [] \n",
    "for i in dataFromEpohAccuracyHuge:\n",
    "    newListQMC.append((i.cpu().detach().numpy()) )\n",
    "newListQMC = sorted(newListQMC, reverse=True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "newListHuje = newListQMC\n",
    "plt.plot(newListHuje)\n",
    "plt.savefig(\"HugeTrain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SmallModel\n",
    "\n",
    "netSmall = torch.nn.ModuleList()\n",
    "complex_cur = 0\n",
    "COMP_netSmall = []\n",
    "SCR_netSmall = []\n",
    "\n",
    "\n",
    "dataFromEpohAccuracySmall = []\n",
    "dataFromEpohLossSmall = []\n",
    "\n",
    "\n",
    "netSmall.append(Cell_try_2(M=3, D=zz[0], Poly_order=4))\n",
    "netSmall.append(Cell_try_2(M=3, D=zz[1], Poly_order=4))\n",
    "netSmall.append(Cell_try_2(M=3, D=zz[2], Poly_order=4))\n",
    "netSmall.append(Cell_try_2(M=3, D=zz[3], Poly_order=4))\n",
    "netSmall.append(Cell_try_2(M=3, D=zz[4], Poly_order=4))\n",
    "\n",
    "\n",
    "\n",
    "netSmall = netSmall.to(torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(netSmall.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "netSmall.train()\n",
    "\n",
    "train( train_queue, valid_queue, netSmall, loss_fn, optimizer,20,scheduler,save_flag=False, dataFromEpohAccuracy = dataFromEpohAccuracySmall, dataFromEpohLoss =dataFromEpohLossSmall)\n",
    "\n",
    "loss_cur, accuracy_cur = eval_model(valid_queue, netSmall, loss_fn)\n",
    "score_cur = accuracy_cur.item()\n",
    "\n",
    "COMP_netSmall.append(complex_cur)\n",
    "SCR_netSmall.append(score_cur)\n",
    "\n",
    "print( score_cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newListQMC = [] \n",
    "for i in dataFromEpohAccuracySmall:\n",
    "    newListQMC.append((i.cpu().detach().numpy()) )\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(newListQMC)\n",
    "plt.savefig(\"SmallTrain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UltraGraf\n",
    "ultraList = [newList,  newListRandom,  newListQMC, newListNSGAII,  newListCMA,  newListHuje]\n",
    "#count = 1 \n",
    "#for i in ultraList:\n",
    "#    plt.plot (i, label = str(count))\n",
    "#    count += 1 \n",
    "#plt.legend()\n",
    "newListCMA = newListCMA[:20]\n",
    "plt.plot(newList, label = \"TPE\")\n",
    "plt.plot(newListRandom, label = \"Random\")\n",
    "plt.plot(newListQMC, label = \"QMC\")\n",
    "plt.plot(newListNSGAII, label = \"GA\")\n",
    "plt.plot(newListCMA, label = \"CMA-E\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"grafShod.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outTPE = sum(list(map( lambda n: n(input_batch),  net)))\n",
    "outRandom = sum(list(map( lambda n: n(input_batch),  netRandom)))\n",
    "outQMC = sum(list(map( lambda n: n(input_batch),  netQMC)))\n",
    "outNSGAII = sum(list(map( lambda n: n(input_batch),  netNSGAII)))\n",
    "outCMA_EA = sum(list(map( lambda n: n(input_batch),  netCMA_EA)))\n",
    "outHuge = sum(list(map( lambda n: n(input_batch),  netHuge)))\n",
    "outTPE = sum(list(map( lambda n: n(input_batch),  netTPE)))\n",
    "outSmall = sum(list(map( lambda n: n(input_batch),  netSmall)))\n",
    "\n",
    "print (outSmall)\n",
    "torch.save(outSmall, 'outSmall.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(outQMC, 'outQMC.pt')\n",
    "torch.save(outNSGAII, 'outNSGAII.pt')\n",
    "torch.save(outCMA_EA, 'outCMA_EA.pt')\n",
    "torch.save(outHuge, 'outHuge.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outQMC = torch.load('outQMC.pt')\n",
    "outNSGAII = torch.load( 'outNSGAII.pt')\n",
    "outCMA_EA = torch.load( 'outCMA_EA.pt')\n",
    "outHuge = torch.load( 'outHuge.pt')\n",
    "outSmall = torch.load( 'outSmall.pt')\n",
    "outTPE = torch.load( 'outTPE.pt')\n",
    "outRandom = torch.load( 'outRandom.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "#input_signal = Variable(valid_queue[:,:,:1],requires_grad=False).permute(2,1,0).cpu()\n",
    "\n",
    "#out_228 = net(valid_queue)\n",
    "\n",
    "for step, (valid) in enumerate(valid_queue):\n",
    "    net.eval()\n",
    "    print(\"Valid: \", type(valid)) \n",
    "    print( \"Valid_queue: \", type(valid_queue))\n",
    "    \n",
    "    input_batch = Variable(valid[:,:,:1],requires_grad=False).permute(2,1,0).cpu()\n",
    "    desired = Variable(valid[:,:,1:],requires_grad=False).permute(2,1,0).cpu()\n",
    "    #out = model.forward(input_batch)\n",
    "    outTPE = sum(list(map( lambda n: n(input_batch),  netTPE)))\n",
    "    outRandom = sum(list(map( lambda n: n(input_batch),  netRandom)))\n",
    "    outQMC = sum(list(map( lambda n: n(input_batch),  netQMC)))\n",
    "    outNSGAII = sum(list(map( lambda n: n(input_batch),  netNSGAII)))\n",
    "    outCMA_EA = sum(list(map( lambda n: n(input_batch),  netCMA_EA)))\n",
    "\n",
    "    \n",
    "    plt.psd(((desired-outTPE).detach().cpu()[0,0,:]+1j*(desired-outTPE).detach().cpu()[0,1,:]),NFFT=2048, label='Error reference', ls='--', c='m')\n",
    "    plt.psd(((outTPE).detach().cpu()[0,0,:]+1j*(outTPE).detach().cpu()[0,1,:]),NFFT=2048, label='1 model  out', ls='--', c='g')\n",
    "\n",
    "\n",
    "    plt.psd((input_batch.detach().cpu()[:,0,0]+1j*input_batch.detach().cpu()[:,1,0]),NFFT=2048,label=' Signal',c='r')\n",
    "    plt.psd(d.reshape(-1,),NFFT=2048,label='Desired',color='orange')\n",
    "    plt.psd(((desired).detach().cpu()[0,0,:]+1j*(desired).detach().cpu()[0,1,:]),NFFT=2048, label='1 model desired', ls='--', c='pink')\n",
    "\n",
    "    plt.legend()\n",
    "    #loss=criterion(out,desired)\n",
    "    #draw_spectrum(input_batch,desired,out)\n",
    "    accuracy = NMSE(input_batch, outTPE - desired)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (valid) in enumerate(valid_queue):\n",
    "    desired = Variable(valid[:,:,1:],requires_grad=False).permute(2,1,0).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "\n",
    "print (type(outTPE))\n",
    "print (type(input_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(input_batch)\n",
    "plt.psd(X.detach().cpu()[:,0,0]+1j*X.detach().cpu()[:,1,0],NFFT=2048, label = \"X\")\n",
    "plt.psd(input_batch.detach().numpy().reshape(-1,),NFFT=2048, label = \"input_batch\")\n",
    "\n",
    "plt.psd(out.detach().numpy().reshape(-1,),NFFT=2048, label = \"out\")\n",
    "plt.psd(out322.detach().numpy().reshape(-1,),NFFT=2048, label = \"out322\")\n",
    "\n",
    "#plt.psd(input_batch.detach().numpy().reshape(-1,),NFFT=2048, label = \"input_batch\")\n",
    "plt.psd(desired.detach().numpy().reshape(-1,),NFFT=2048, label = \"desired\")\n",
    "plt.psd((out - desired).detach().numpy().reshape(-1,),NFFT=2048, label = \"minus\")\n",
    "plt.psd(d.reshape(-1,),NFFT=2048, label = \"d\",ls='--')\n",
    "plt.psd(ref.reshape(-1,),NFFT=2048, label = \"ref\",ls='--')\n",
    "#plt.psd(D.reshape(-1,),NFFT=2048, label = \"d\")\n",
    "#plt.psd(X.reshape(-1,),NFFT=2048, label = \"x\")\n",
    "#plt.psd(ref.reshape(-1,),NFFT=2048, label = \"ref\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from Data.utilits.draw_functions import plot_psd_complex2\n",
    "X2 = X\n",
    "X2 = torch.permute(X2, (2, 1, 0))\n",
    "justnumber = 4\n",
    "plot_psd_complex3 ({ \n",
    "                    \"Signal\" : ((X.detach().cpu()[:,0,0]+1j*X.detach().cpu()[:,1,0]) / 2**15 )*justnumber,\n",
    "                    (\"Desired\"):(((desired).detach().cpu()[0,0,:]+1j*(desired).detach().cpu()[0,1,:])/2**15)*justnumber,\n",
    "                   \"TPE\" : (((desired - outTPE + X2  ).detach().cpu()[0,0,:]+1j*(desired - outTPE + X2).detach().cpu()[0,1,:])/2**15)*justnumber, \n",
    "                   \"Random\":((desired - outRandom + X2 ).detach().cpu()[0,0,:]/2**15+1j*(desired - outRandom + X2 ).detach().cpu()[0,1,:]/2**15)*justnumber,\n",
    "                  \"NSGAII\":((desired - outNSGAII + X2  ).detach().cpu()[0,0,:]/2**15+1j*(desired - outNSGAII + X2 ).detach().cpu()[0,1,:]/2**15)*justnumber,\n",
    "                   \"QMC\":((desired - outQMC + X2 ).detach().cpu()[0,0,:]/2**15+1j*(desired - outQMC + X2).detach().cpu()[0,1,:]/2**15)*justnumber,\n",
    "                  \"CMA-EA\":((desired - outCMA_EA + X2 ).detach().cpu()[0,0,:]/2**15+1j*(desired - outCMA_EA + X2).detach().cpu()[0,1,:]/2**15)*justnumber, \n",
    "                   \"Huge model\" :  ((desired - outHuge + X2 ).detach().cpu()[0,0,:]/2**15+1j*(desired - outHuge + X2).detach().cpu()[0,1,:]/2**15)*justnumber,                                                                                }, fs=4*122.88,\n",
    "                 )\n",
    "plt.legend(prop={'size': 7})\n",
    "plt.savefig(\"PowerSP_Freq.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMSE(outNSGAII , outTPE)\n",
    "NMSE(outNSGAII , outTPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.utilits import ACPR_calc\n",
    "\n",
    "error = (desired - outNSGAII + X2  ).detach().cpu()[0,0,:]+1j*(desired - outNSGAII + X2).detach().cpu()[0,1,:]\n",
    "Xcom = (X.detach().cpu()[:,0,0]+1j*X.detach().cpu()[:,1,0])\n",
    "print(error)\n",
    "acpr = ACPR_calc(Xcom.cpu().detach().numpy().reshape(-1)+\n",
    "            (error ).cpu().detach().numpy().reshape(-1),4*122.88e6,  10e6,-72e6,52e6,20e6,20e6)\n",
    "print('ACPR={}'.format(acpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_psd_complex2 ({ \n",
    "    #\"Desired\":(((torch.nn.functional.normalize(desired,dim = 1)).detach().cpu()[0,0,:]+1j*((torch.nn.functional.normalize(desired,dim = 1))).detach().cpu()[0,1,:])/2**15)+justnumber,\n",
    "                  (\"Signal\", '--', 0.3, \"_\",12 ) : ( torch.nn.functional.normalize(X,dim = 1).detach().cpu()[:,0,0]+1j*torch.nn.functional.normalize(X,dim = 1).detach().cpu()[:,1,0]) / 2**15 ,\n",
    "                    (\"Desired\"):(((torch.nn.functional.normalize(desired,dim = 1) ).detach().cpu()[0,0,:]+1j*(torch.nn.functional.normalize(desired,dim = 1)).detach().cpu()[0,1,:])/2**15)+justnumber,\n",
    "                    \"TPE\" : (((TPE2  ).detach().cpu()[0,0,:]+1j*( TPE2).detach().cpu()[0,1,:])/2**15)+justnumber, \n",
    "                   \"Random\":(( Random2 ).detach().cpu()[0,0,:]/2**15+1j*( Random2 ).detach().cpu()[0,1,:]/2**15)+justnumber,\n",
    "                  \"NSGAII\":(( NSGAII2  ).detach().cpu()[0,0,:]/2**15+1j*( NSGAII2 ).detach().cpu()[0,1,:]/2**15)+justnumber,\n",
    "                   \"QMC\":(( QMC2  ).detach().cpu()[0,0,:]/2**15+1j*( QMC2 ).detach().cpu()[0,1,:]/2**15)+justnumber,\n",
    "                  \"CMA-EA\":(( CMA_EA2 ).detach().cpu()[0,0,:]/2**15+1j*( CMA_EA2).detach().cpu()[0,1,:]/2**15)+justnumber,\n",
    "\n",
    "}, fs=4*122.88, name = \"Graf1.png\"\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPE2 = outTPE\n",
    "Random2 = outRandom\n",
    "NSGAII2 = outNSGAII\n",
    "QMC2 = outQMC\n",
    "CMA_EA2 = outCMA_EA\n",
    "\n",
    "\n",
    "XNorm = X\n",
    "XNorm = torch.permute(XNorm, (2, 1, 0))\n",
    "print (XNorm.shape)\n",
    "\n",
    "TPE2 = (torch.nn.functional.normalize(desired,dim = 1) - torch.nn.functional.normalize(TPE2,dim = 1) ) +  XNorm \n",
    "Random2 = (torch.nn.functional.normalize(desired,dim = 1) - torch.nn.functional.normalize(Random2,dim = 1) ) +  XNorm \n",
    "NSGAII2 = (torch.nn.functional.normalize(desired,dim = 1) - torch.nn.functional.normalize(NSGAII2,dim = 1) ) +  XNorm \n",
    "QMC2 = (torch.nn.functional.normalize(desired,dim = 1) - torch.nn.functional.normalize(QMC2,dim = 1) ) +  XNorm \n",
    "CMA_EA2 = (torch.nn.functional.normalize(desired,dim = 1) - torch.nn.functional.normalize(CMA_EA2,dim = 1) ) +  XNorm \n",
    "\n",
    "print (TPE2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psd_complex2(*signals, fs: float, N: int = 2048, window: str = 'hann',name: str = 'pic.png'):\n",
    "    \"\"\"Compute PSD of multiple signals using Welch method and plot them\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signals :\n",
    "        dictionary of signals to compute PSD,\n",
    "        format:\n",
    "        1st variant: {(\"name_1\", ls, lw, marker, markersize): signal_1, (\"name_2\", ls, lw, marker, markersize): signal_2, ...}\n",
    "        2nd variant: {\"name_1\": signal_1, \"name_2\": signal_2, ...}, format can be choosen separately for each plot\n",
    "    fs : float              4*122.88\n",
    "        sampling frequency [MHz]\n",
    "    N : int, optional\n",
    "        window size, by default 2048\n",
    "    window : str, optional\n",
    "        window type (windows are taken from `sp.signal.windows`), by default 'hann'\n",
    "    \"\"\"\n",
    "\n",
    "    # defaults\n",
    "    ls = '-'\n",
    "    lw = 0.3\n",
    "    marker = '.'\n",
    "    markersize = 0.5\n",
    "    color = ['blue','red','green','purple','orange', 'olive','gray','black']\n",
    "    plt.figure()\n",
    "    plt.xlabel('Freq [MHz]')\n",
    "    plt.ylabel('Power Spectrum [dB]')\n",
    "    for info, s in signals[0].items():\n",
    "        if type(info) != tuple:\n",
    "            info = (info, ls, lw, marker, markersize)\n",
    "\n",
    "        # default detrend removes dc\n",
    "        f_psd, signal_psd = sp.signal.welch(x=s, fs=fs, scaling='spectrum', return_onesided=False, detrend=False,\n",
    "                                            window=sp.signal.get_window(window, N))\n",
    "        arg_sort = np.argsort(f_psd)\n",
    "        f_psd = np.roll(f_psd, N // 2, axis=0)\n",
    "        signal_psd = np.roll(signal_psd, N // 2, axis=0)\n",
    "        if c\n",
    "        plt.plot(f_psd, 10 * np.log10(signal_psd), label=info[0], ls=info[1], lw=info[2], marker=info[3],\n",
    "                 markersize=info[4])\n",
    "    plt.xlim(-100, 100)\n",
    "    #plt.ylim(-25, 5 )\n",
    "\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.grid('both')\n",
    "    #plt.savefig(name)\n",
    "\n",
    "   # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psd_complex3(*signals, fs: float, N: int = 2048, window: str = 'hann',name: str = 'pic.png'):\n",
    "    \"\"\"Compute PSD of multiple signals using Welch method and plot them\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signals :\n",
    "        dictionary of signals to compute PSD,\n",
    "        format:\n",
    "        1st variant: {(\"name_1\", ls, lw, marker, markersize): signal_1, (\"name_2\", ls, lw, marker, markersize): signal_2, ...}\n",
    "        2nd variant: {\"name_1\": signal_1, \"name_2\": signal_2, ...}, format can be choosen separately for each plot\n",
    "    fs : float              4*122.88\n",
    "        sampling frequency [MHz]\n",
    "    N : int, optional\n",
    "        window size, by default 2048\n",
    "    window : str, optional\n",
    "        window type (windows are taken from `sp.signal.windows`), by default 'hann'\n",
    "    \"\"\"\n",
    "\n",
    "    # defaults\n",
    "    ls = '-'\n",
    "    lw = 0.3\n",
    "    marker = '.'\n",
    "    markersize = 0.5\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Freq [MHz]')\n",
    "    plt.ylabel('Power Spectrum [dB]')\n",
    "    color = ['blue','red','green','purple','orange', 'olive','gray','black']\n",
    "    countColor = 0\n",
    "    for info, s in signals[0].items():\n",
    "        if type(info) != tuple:\n",
    "            info = (info, ls, lw, marker, markersize)\n",
    "\n",
    "        # default detrend removes dc\n",
    "        f_psd, signal_psd = sp.signal.welch(x=s, fs=fs, scaling='spectrum', return_onesided=False, detrend=False,\n",
    "                                            window=sp.signal.get_window(window, N))\n",
    "        arg_sort = np.argsort(f_psd)\n",
    "        f_psd = np.roll(f_psd, N // 2, axis=0)\n",
    "        signal_psd = np.roll(signal_psd, N // 2, axis=0)\n",
    "        if countColor == 0:\n",
    "            plt.plot(f_psd, 10 * np.log10(signal_psd)+114, label=info[0], ls=info[1], lw=2, marker=info[3],\n",
    "                 markersize=info[4],c=color[countColor])\n",
    "        else:\n",
    "            plt.plot(f_psd, 10 * np.log10(signal_psd)+114, label=info[0], ls=info[1], lw=info[2], marker=info[3],\n",
    "                 markersize=info[4],c=color[countColor])\n",
    "        countColor += 1 \n",
    "    plt.xlim(-150, 150)\n",
    "    plt.ylim(-90, 5 )\n",
    "\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.grid('both')\n",
    "    #plt.savefig(name)\n",
    "\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complex_huge)\n",
    "### params of the functional\n",
    "score_huge = -33.88\n",
    "score_min = -20.0\n",
    "complex_huge = sum(ref_model['k']) + sum(ref_model['p'])\n",
    "complex_min = 4 * 5 + 3 * 5\n",
    "\n",
    "COMP_netHuge \n",
    "SCR_netHuge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SCR_netHuge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1375edf037505a6feabed610fafe9d30e3d91e38d5d857467887f9ed33ac4531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
